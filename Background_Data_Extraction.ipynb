{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Background Data Extraction for Site Analysis\n",
        "\n",
        "This notebook extracts background environmental data for any Area of Interest (AOI):\n",
        "- **AAFC Annual Crop Inventory**: Historical crop types for each year\n",
        "- **ERA-5 Land Precipitation**: Monthly precipitation with anomaly analysis\n",
        "\n",
        "Simply upload your AOI polygon, specify the date range, and export the combined dataset as CSV for use in other analyses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Authentication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import ee\n",
        "import geemap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import json\n",
        "import os\n",
        "from io import BytesIO\n",
        "import zipfile\n",
        "import calendar\n",
        "from datetime import datetime\n",
        "import geopandas as gpd\n",
        "import fiona\n",
        "\n",
        "# Set pandas display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_rows', 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Earth Engine\n",
        "try:\n",
        "    ee.Initialize()\n",
        "    print(\"✓ Earth Engine initialized successfully\")\n",
        "except:\n",
        "    print(\"Authenticating with Earth Engine...\")\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize(project=\"jessemapping\")  # Replace with your GEE project ID\n",
        "    print(\"✓ Earth Engine initialized successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. AOI Upload and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global variables for storing geometries\n",
        "aoi_geometry = None\n",
        "uploaded_filename = None\n",
        "\n",
        "def parse_kml(content):\n",
        "    \"\"\"Parse KML content and extract geometry\"\"\"\n",
        "    try:\n",
        "        import xml.etree.ElementTree as ET\n",
        "        root = ET.fromstring(content)\n",
        "        \n",
        "        # Handle KML namespaces\n",
        "        namespaces = {'kml': 'http://www.opengis.net/kml/2.2'}\n",
        "        \n",
        "        # Find all coordinates\n",
        "        coords_elements = root.findall('.//kml:coordinates', namespaces)\n",
        "        if not coords_elements:\n",
        "            # Try without namespace\n",
        "            coords_elements = root.findall('.//coordinates')\n",
        "        \n",
        "        if coords_elements:\n",
        "            coords_text = coords_elements[0].text.strip()\n",
        "            # Parse coordinates (format: lon,lat,alt or lon,lat)\n",
        "            coords = []\n",
        "            for point in coords_text.split():\n",
        "                parts = point.split(',')\n",
        "                if len(parts) >= 2:\n",
        "                    coords.append([float(parts[0]), float(parts[1])])\n",
        "            return ee.Geometry.Polygon([coords])\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing KML: {e}\")\n",
        "        return None\n",
        "\n",
        "def parse_geojson(content):\n",
        "    \"\"\"Parse GeoJSON content and extract geometry\"\"\"\n",
        "    try:\n",
        "        geojson_dict = json.loads(content)\n",
        "        \n",
        "        # Handle different GeoJSON structures\n",
        "        if geojson_dict.get('type') == 'FeatureCollection':\n",
        "            # Get first feature\n",
        "            if geojson_dict.get('features'):\n",
        "                feature = geojson_dict['features'][0]\n",
        "                return ee.Geometry(feature['geometry'])\n",
        "        elif geojson_dict.get('type') == 'Feature':\n",
        "            return ee.Geometry(geojson_dict['geometry'])\n",
        "        elif geojson_dict.get('type') in ['Polygon', 'MultiPolygon', 'Point']:\n",
        "            return ee.Geometry(geojson_dict)\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing GeoJSON: {e}\")\n",
        "        return None\n",
        "\n",
        "def parse_shapefile(file_contents, filename):\n",
        "    \"\"\"Parse shapefile (from zip) and extract geometry\"\"\"\n",
        "    try:\n",
        "        # Save uploaded file temporarily\n",
        "        import tempfile\n",
        "        import shutil\n",
        "        \n",
        "        with tempfile.TemporaryDirectory() as tmpdir:\n",
        "            # Handle ZIP file\n",
        "            if filename.endswith('.zip'):\n",
        "                with zipfile.ZipFile(BytesIO(file_contents)) as zf:\n",
        "                    zf.extractall(tmpdir)\n",
        "                \n",
        "                # Find the .shp file\n",
        "                shp_files = [f for f in os.listdir(tmpdir) if f.endswith('.shp')]\n",
        "                if not shp_files:\n",
        "                    print(\"No .shp file found in the ZIP archive\")\n",
        "                    return None\n",
        "                \n",
        "                shp_path = os.path.join(tmpdir, shp_files[0])\n",
        "            else:\n",
        "                # Single .shp file\n",
        "                shp_path = os.path.join(tmpdir, filename)\n",
        "                with open(shp_path, 'wb') as f:\n",
        "                    f.write(file_contents)\n",
        "            \n",
        "            # Read with geopandas\n",
        "            gdf = gpd.read_file(shp_path)\n",
        "            \n",
        "            # Convert to Earth Engine geometry\n",
        "            # Get the first geometry\n",
        "            geom = gdf.geometry.iloc[0]\n",
        "            \n",
        "            # Convert to GeoJSON then to Earth Engine\n",
        "            geojson = geom.__geo_interface__\n",
        "            return ee.Geometry(geojson)\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing shapefile: {e}\")\n",
        "        return None\n",
        "\n",
        "def handle_upload(change):\n",
        "    \"\"\"Handle file upload and parse geometry\"\"\"\n",
        "    global aoi_geometry, uploaded_filename\n",
        "    \n",
        "    if change['new']:\n",
        "        uploaded_file = change['new'][0]\n",
        "        filename = uploaded_file['name']\n",
        "        content = uploaded_file['content']\n",
        "        \n",
        "        uploaded_filename = filename\n",
        "        print(f\"Processing: {filename}\")\n",
        "        \n",
        "        # Parse based on file type\n",
        "        if filename.endswith('.kml'):\n",
        "            aoi_geometry = parse_kml(content.decode('utf-8'))\n",
        "        elif filename.endswith('.geojson') or filename.endswith('.json'):\n",
        "            aoi_geometry = parse_geojson(content.decode('utf-8'))\n",
        "        elif filename.endswith('.zip') or filename.endswith('.shp'):\n",
        "            aoi_geometry = parse_shapefile(content, filename)\n",
        "        else:\n",
        "            print(f\"Unsupported file type: {filename}\")\n",
        "            return\n",
        "        \n",
        "        if aoi_geometry:\n",
        "            # Calculate area\n",
        "            area = aoi_geometry.area().divide(10000).getInfo()  # Convert to hectares\n",
        "            print(f\"✓ AOI loaded successfully!\")\n",
        "            print(f\"  Area: {area:.2f} hectares\")\n",
        "            \n",
        "            # Get centroid for display\n",
        "            centroid = aoi_geometry.centroid().coordinates().getInfo()\n",
        "            print(f\"  Centroid: {centroid[1]:.5f}°N, {centroid[0]:.5f}°W\")\n",
        "            \n",
        "            # Update status\n",
        "            status_output.clear_output()\n",
        "            with status_output:\n",
        "                display(HTML(f'<div style=\"color: green; font-weight: bold;\">✓ AOI loaded: {area:.1f} ha</div>'))\n",
        "        else:\n",
        "            status_output.clear_output()\n",
        "            with status_output:\n",
        "                display(HTML('<div style=\"color: red;\">⚠ Failed to parse geometry</div>'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create upload widget\n",
        "upload_widget = widgets.FileUpload(\n",
        "    accept='.kml,.geojson,.json,.zip,.shp',\n",
        "    multiple=False,\n",
        "    description='Upload AOI:',\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "# Status output\n",
        "status_output = widgets.Output()\n",
        "\n",
        "# Connect handler\n",
        "upload_widget.observe(handle_upload, names='value')\n",
        "\n",
        "# Display widgets\n",
        "print(\"Upload your Area of Interest (AOI) polygon:\")\n",
        "print(\"Supported formats: KML, GeoJSON, Shapefile (SHP/ZIP)\")\n",
        "display(upload_widget)\n",
        "display(status_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configure Analysis Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Date range configuration\n",
        "current_year = datetime.now().year\n",
        "\n",
        "# AAFC date range (available 2009-2023)\n",
        "aafc_start = widgets.IntSlider(\n",
        "    value=2017,\n",
        "    min=2009,\n",
        "    max=2023,\n",
        "    step=1,\n",
        "    description='AAFC Start:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "aafc_end = widgets.IntSlider(\n",
        "    value=2023,\n",
        "    min=2009,\n",
        "    max=2023,\n",
        "    step=1,\n",
        "    description='AAFC End:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# Precipitation baseline period\n",
        "precip_baseline_start = widgets.IntSlider(\n",
        "    value=2010,\n",
        "    min=1980,\n",
        "    max=current_year-1,\n",
        "    step=1,\n",
        "    description='Baseline Start:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "precip_baseline_end = widgets.IntSlider(\n",
        "    value=2019,\n",
        "    min=1980,\n",
        "    max=current_year-1,\n",
        "    step=1,\n",
        "    description='Baseline End:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# Analysis years for precipitation\n",
        "precip_analysis_start = widgets.IntSlider(\n",
        "    value=2017,\n",
        "    min=1980,\n",
        "    max=current_year,\n",
        "    step=1,\n",
        "    description='Analysis Start:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "precip_analysis_end = widgets.IntSlider(\n",
        "    value=2023,\n",
        "    min=1980,\n",
        "    max=current_year,\n",
        "    step=1,\n",
        "    description='Analysis End:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "print(\"Configure Date Ranges:\")\n",
        "print(\"\\nAAFC Crop Inventory:\")\n",
        "display(aafc_start, aafc_end)\n",
        "print(\"\\nPrecipitation Baseline Period (for calculating 'normal'):\")\n",
        "display(precip_baseline_start, precip_baseline_end)\n",
        "print(\"\\nPrecipitation Analysis Years:\")\n",
        "display(precip_analysis_start, precip_analysis_end)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Extract AAFC Crop History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AAFC crop classification codes\n",
        "CROP_CLASSES = {\n",
        "    10: 'Built-up',\n",
        "    20: 'Water',\n",
        "    30: 'Exposed and/or Barren Land',\n",
        "    34: 'Developed',\n",
        "    35: 'Shrubland',\n",
        "    50: 'Grassland',\n",
        "    80: 'Wetland',\n",
        "    110: 'Annual Crop (undifferentiated)',\n",
        "    120: 'Berries',\n",
        "    121: 'Blueberry',\n",
        "    122: 'Cranberry',\n",
        "    130: 'Orchard',\n",
        "    131: 'Other Orchard',\n",
        "    132: 'Vineyard',\n",
        "    133: 'Hops',\n",
        "    136: 'Other Vegetables',\n",
        "    137: 'Asparagus',\n",
        "    139: 'Onions',\n",
        "    140: 'Potato',\n",
        "    141: 'Sweet Potato',\n",
        "    145: 'Sugar Beets',\n",
        "    146: 'Spring Wheat',\n",
        "    147: 'Winter Wheat',\n",
        "    148: 'Wheat (undifferentiated)',\n",
        "    150: 'Switchgrass',\n",
        "    151: 'Tobacco',\n",
        "    152: 'Ginseng',\n",
        "    153: 'Canola and Rapeseed',\n",
        "    154: 'Flaxseed',\n",
        "    155: 'Safflower',\n",
        "    156: 'Sunflower',\n",
        "    157: 'Soybeans',\n",
        "    158: 'Peas',\n",
        "    160: 'Barley',\n",
        "    161: 'Oats',\n",
        "    162: 'Corn',\n",
        "    163: 'Triticale',\n",
        "    165: 'Millet',\n",
        "    166: 'Rye',\n",
        "    167: 'Spelt',\n",
        "    174: 'Beans',\n",
        "    175: 'Fababeans',\n",
        "    176: 'Lentils',\n",
        "    177: 'Vegetables (undifferentiated)',\n",
        "    178: 'Tomatoes',\n",
        "    179: 'Pumpkins',\n",
        "    180: 'Squash',\n",
        "    181: 'Lettuce',\n",
        "    182: 'Spinach',\n",
        "    183: 'Beets',\n",
        "    184: 'Carrots',\n",
        "    185: 'Cabbage',\n",
        "    187: 'Peppers',\n",
        "    188: 'Eggplants',\n",
        "    189: 'Radishes',\n",
        "    191: 'Garlic',\n",
        "    192: 'Sod',\n",
        "    193: 'Herbs',\n",
        "    194: 'Nursery',\n",
        "    195: 'Buckwheat',\n",
        "    196: 'Canaryseed',\n",
        "    197: 'Hemp',\n",
        "    198: 'Vetch',\n",
        "    199: 'Other Crops',\n",
        "    200: 'Forest (undifferentiated)',\n",
        "    210: 'Coniferous',\n",
        "    220: 'Broadleaf',\n",
        "    230: 'Mixedwood'\n",
        "}\n",
        "\n",
        "def extract_aafc_crop_history(geometry, start_year, end_year):\n",
        "    \"\"\"Extract AAFC crop history for the AOI\"\"\"\n",
        "    aafc = ee.ImageCollection('AAFC/ACI')\n",
        "    crop_history = []\n",
        "    \n",
        "    for year in range(start_year, end_year + 1):\n",
        "        # Get crop inventory for this year\n",
        "        crop_collection = aafc.filter(ee.Filter.date(f'{year}-01-01', f'{year}-12-31'))\n",
        "        \n",
        "        # Check if collection has images\n",
        "        collection_size = crop_collection.size()\n",
        "        \n",
        "        if collection_size.getInfo() > 0:\n",
        "            crop_img = crop_collection.first()\n",
        "            # Sample pixels within the geometry\n",
        "            samples = crop_img.select('landcover').sample(\n",
        "                region=geometry,\n",
        "                scale=30,\n",
        "                numPixels=500,\n",
        "                seed=year,\n",
        "                geometries=False\n",
        "            )\n",
        "            \n",
        "            # Get mode (most frequent crop)\n",
        "            sample_list = samples.aggregate_array('landcover').getInfo()\n",
        "            \n",
        "            if sample_list:\n",
        "                from collections import Counter\n",
        "                code_counts = Counter(sample_list)\n",
        "                most_common = code_counts.most_common(3)  # Get top 3 crops\n",
        "                \n",
        "                # Primary crop\n",
        "                primary_code = most_common[0][0]\n",
        "                primary_count = most_common[0][1]\n",
        "                primary_pct = (primary_count / len(sample_list)) * 100\n",
        "                \n",
        "                crop_history.append({\n",
        "    'Year': year,\n",
        "                    'Primary_Crop_Code': primary_code,\n",
        "                    'Primary_Crop': CROP_CLASSES.get(primary_code, f'Unknown ({primary_code})'),\n",
        "                    'Primary_Crop_Pct': round(primary_pct, 1),\n",
        "                    'Secondary_Crop': CROP_CLASSES.get(most_common[1][0], 'None') if len(most_common) > 1 else 'None',\n",
        "                    'Total_Samples': len(sample_list)\n",
        "                })\n",
        "            else:\n",
        "                crop_history.append({\n",
        "                    'Year': year,\n",
        "                    'Primary_Crop_Code': None,\n",
        "                    'Primary_Crop': 'No Data',\n",
        "                    'Primary_Crop_Pct': 0,\n",
        "                    'Secondary_Crop': 'None',\n",
        "                    'Total_Samples': 0\n",
        "                })\n",
        "        else:\n",
        "            crop_history.append({\n",
        "                'Year': year,\n",
        "                'Primary_Crop_Code': None,\n",
        "                'Primary_Crop': 'No AAFC Data',\n",
        "                'Primary_Crop_Pct': 0,\n",
        "                'Secondary_Crop': 'None',\n",
        "                'Total_Samples': 0\n",
        "            })\n",
        "    \n",
        "    return pd.DataFrame(crop_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract AAFC data\n",
        "if aoi_geometry:\n",
        "    print(f\"Extracting AAFC crop history ({aafc_start.value}-{aafc_end.value})...\")\n",
        "    aafc_df = extract_aafc_crop_history(aoi_geometry, aafc_start.value, aafc_end.value)\n",
        "    \n",
        "    print(\"\\nCrop History:\")\n",
        "    display(aafc_df)\n",
        "    \n",
        "    # Visualize crop rotation\n",
        "    if len(aafc_df) > 0:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        \n",
        "        # Get unique crops and assign colors\n",
        "        unique_crops = aafc_df['Primary_Crop'].unique()\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, len(unique_crops)))\n",
        "        crop_colors = dict(zip(unique_crops, colors))\n",
        "        \n",
        "        # Create bar chart\n",
        "        bars = ax.bar(aafc_df['Year'], [1]*len(aafc_df), \n",
        "                      color=[crop_colors[crop] for crop in aafc_df['Primary_Crop']])\n",
        "        \n",
        "        # Add crop labels\n",
        "        for i, (year, crop) in enumerate(zip(aafc_df['Year'], aafc_df['Primary_Crop'])):\n",
        "            ax.text(year, 0.5, crop[:10], ha='center', va='center', rotation=90, fontsize=9)\n",
        "        \n",
        "        ax.set_xlabel('Year', fontsize=12)\n",
        "        ax.set_ylabel('Crop Type', fontsize=12)\n",
        "        ax.set_title('Crop Rotation History', fontsize=14, fontweight='bold')\n",
        "        ax.set_ylim(0, 1)\n",
        "        ax.set_yticks([])\n",
        "        \n",
        "        # Create legend\n",
        "        legend_elements = [plt.Rectangle((0,0),1,1, fc=crop_colors[crop], label=crop) \n",
        "                          for crop in unique_crops]\n",
        "        ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1, 1))\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"⚠ Please upload an AOI first\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Extract ERA-5 Precipitation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_monthly_precipitation(geometry, year, months=None):\n",
        "    \"\"\"Extract monthly precipitation from ERA-5 Land\"\"\"\n",
        "    if months is None:\n",
        "        months = list(range(4, 11))  # April to October\n",
        "    \n",
        "    monthly_data = []\n",
        "    era5_collection = 'ECMWF/ERA5_LAND/MONTHLY_AGGR'\n",
        "    \n",
        "    for month in months:\n",
        "        start_date = f'{year}-{month:02d}-01'\n",
        "        last_day = calendar.monthrange(year, month)[1]\n",
        "        end_date = f'{year}-{month:02d}-{last_day}'\n",
        "        \n",
        "        # Load ERA5-Land monthly data\n",
        "        era5_collection_ee = ee.ImageCollection(era5_collection).filter(\n",
        "            ee.Filter.date(start_date, end_date)\n",
        "        )\n",
        "        \n",
        "        # Check if collection has images\n",
        "        collection_size = era5_collection_ee.size()\n",
        "        \n",
        "        if collection_size.getInfo() > 0:\n",
        "            era5 = era5_collection_ee.first()\n",
        "            \n",
        "            # Extract total precipitation (m to mm conversion)\n",
        "            precip = era5.select('total_precipitation_sum').multiply(1000)\n",
        "            \n",
        "            # Calculate mean precipitation over geometry\n",
        "            stats = precip.reduceRegion(\n",
        "                reducer=ee.Reducer.mean(),\n",
        "                geometry=geometry,\n",
        "                scale=11132,  # ERA5-Land resolution\n",
        "                maxPixels=1e9\n",
        "            )\n",
        "            \n",
        "            precip_mm = stats.get('total_precipitation_sum').getInfo()\n",
        "            \n",
        "            monthly_data.append({\n",
        "                'Year': year,\n",
        "                'Month': month,\n",
        "                'Month_Name': calendar.month_name[month],\n",
        "                'Precipitation_mm': round(precip_mm, 1)\n",
        "            })\n",
        "        else:\n",
        "            monthly_data.append({\n",
        "                'Year': year,\n",
        "                'Month': month,\n",
        "                'Month_Name': calendar.month_name[month],\n",
        "                'Precipitation_mm': None\n",
        "            })\n",
        "    \n",
        "    return monthly_data\n",
        "\n",
        "def calculate_baseline_statistics(geometry, start_year, end_year):\n",
        "    \"\"\"Calculate baseline precipitation statistics\"\"\"\n",
        "    print(f\"Calculating baseline statistics ({start_year}-{end_year})...\")\n",
        "    baseline_data = {month: [] for month in range(4, 11)}\n",
        "    \n",
        "    for year in range(start_year, end_year + 1):\n",
        "        year_data = extract_monthly_precipitation(geometry, year)\n",
        "        for month_data in year_data:\n",
        "            if month_data['Precipitation_mm'] is not None:\n",
        "                baseline_data[month_data['Month']].append(month_data['Precipitation_mm'])\n",
        "    \n",
        "    # Calculate statistics\n",
        "    baseline_stats = []\n",
        "    for month in range(4, 11):\n",
        "        if len(baseline_data[month]) > 0:\n",
        "            values = np.array(baseline_data[month])\n",
        "            baseline_stats.append({\n",
        "                'Month': month,\n",
        "                'Month_Name': calendar.month_name[month],\n",
        "                'Mean_mm': round(np.mean(values), 1),\n",
        "                'Median_mm': round(np.median(values), 1),\n",
        "                'StdDev': round(np.std(values), 1),\n",
        "                'P10': round(np.percentile(values, 10), 1),\n",
        "                'P25': round(np.percentile(values, 25), 1),\n",
        "                'P75': round(np.percentile(values, 75), 1),\n",
        "                'P90': round(np.percentile(values, 90), 1)\n",
        "            })\n",
        "    \n",
        "    return pd.DataFrame(baseline_stats)\n",
        "\n",
        "def classify_precipitation(value, mean, p10, p25, p75, p90):\n",
        "    \"\"\"Classify precipitation relative to baseline\"\"\"\n",
        "    if value <= p10:\n",
        "        return 'Extremely Dry'\n",
        "    elif value <= p25:\n",
        "        return 'Dry'\n",
        "    elif value <= p75:\n",
        "        return 'Normal'\n",
        "    elif value <= p90:\n",
        "        return 'Wet'\n",
        "    else:\n",
        "        return 'Extremely Wet'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate baseline statistics\n",
        "if aoi_geometry:\n",
        "    print(\"Calculating precipitation baseline statistics...\")\n",
        "    baseline_df = calculate_baseline_statistics(\n",
        "        aoi_geometry, \n",
        "        precip_baseline_start.value, \n",
        "        precip_baseline_end.value\n",
        "    )\n",
        "    \n",
        "    print(\"\\nBaseline Statistics (April-October):\")\n",
        "    display(baseline_df)\n",
        "else:\n",
        "    print(\"⚠ Please upload an AOI first\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract precipitation for analysis years\n",
        "if aoi_geometry:\n",
        "    print(f\"Extracting precipitation data ({precip_analysis_start.value}-{precip_analysis_end.value})...\")\n",
        "    \n",
        "    all_precip_data = []\n",
        "    yearly_summaries = []\n",
        "    \n",
        "    for year in range(precip_analysis_start.value, precip_analysis_end.value + 1):\n",
        "        year_data = extract_monthly_precipitation(aoi_geometry, year)\n",
        "        \n",
        "        # Add classification based on baseline\n",
        "        for month_data in year_data:\n",
        "            month_num = month_data['Month']\n",
        "            baseline_row = baseline_df[baseline_df['Month'] == month_num]\n",
        "            \n",
        "            if not baseline_row.empty and month_data['Precipitation_mm'] is not None:\n",
        "                baseline = baseline_row.iloc[0]\n",
        "                month_data['Normal_mm'] = baseline['Mean_mm']\n",
        "                month_data['Anomaly_mm'] = round(month_data['Precipitation_mm'] - baseline['Mean_mm'], 1)\n",
        "                month_data['Anomaly_pct'] = round((month_data['Anomaly_mm'] / baseline['Mean_mm']) * 100, 1)\n",
        "                month_data['Classification'] = classify_precipitation(\n",
        "                    month_data['Precipitation_mm'],\n",
        "                    baseline['Mean_mm'],\n",
        "                    baseline['P10'],\n",
        "                    baseline['P25'],\n",
        "                    baseline['P75'],\n",
        "                    baseline['P90']\n",
        "                )\n",
        "            else:\n",
        "                month_data['Normal_mm'] = None\n",
        "                month_data['Anomaly_mm'] = None\n",
        "                month_data['Anomaly_pct'] = None\n",
        "                month_data['Classification'] = 'No Data'\n",
        "        \n",
        "        all_precip_data.extend(year_data)\n",
        "        \n",
        "        # Calculate yearly summary\n",
        "        valid_months = [m for m in year_data if m['Precipitation_mm'] is not None]\n",
        "        if valid_months:\n",
        "            total_precip = sum(m['Precipitation_mm'] for m in valid_months)\n",
        "            total_normal = sum(m['Normal_mm'] for m in valid_months if m['Normal_mm'] is not None)\n",
        "            \n",
        "            if total_normal > 0:\n",
        "                anomaly_pct = ((total_precip - total_normal) / total_normal) * 100\n",
        "            else:\n",
        "                anomaly_pct = 0\n",
        "            \n",
        "            # Classify season\n",
        "            if anomaly_pct <= -30:\n",
        "                season_class = 'Extremely Dry Season'\n",
        "            elif anomaly_pct <= -15:\n",
        "                season_class = 'Dry Season'\n",
        "            elif anomaly_pct <= 15:\n",
        "                season_class = 'Normal Season'\n",
        "            elif anomaly_pct <= 30:\n",
        "                season_class = 'Wet Season'\n",
        "            else:\n",
        "                season_class = 'Extremely Wet Season'\n",
        "            \n",
        "            yearly_summaries.append({\n",
        "                'Year': year,\n",
        "                'Total_Precip_mm': round(total_precip, 1),\n",
        "                'Normal_mm': round(total_normal, 1),\n",
        "                'Anomaly_mm': round(total_precip - total_normal, 1),\n",
        "                'Anomaly_pct': round(anomaly_pct, 1),\n",
        "                'Classification': season_class\n",
        "            })\n",
        "    \n",
        "    precip_df = pd.DataFrame(all_precip_data)\n",
        "    yearly_df = pd.DataFrame(yearly_summaries)\n",
        "    \n",
        "    print(\"\\nYearly Precipitation Summary:\")\n",
        "    display(yearly_df)\n",
        "else:\n",
        "    print(\"⚠ Please upload an AOI first\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualization\n",
        "if aoi_geometry and 'yearly_df' in locals():\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    fig.suptitle('Background Environmental Data Analysis', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. Precipitation anomaly chart\n",
        "    ax1 = axes[0, 0]\n",
        "    colors = ['brown' if a < 0 else 'lightblue' for a in yearly_df['Anomaly_pct']]\n",
        "    bars = ax1.bar(yearly_df['Year'], yearly_df['Anomaly_pct'], color=colors, alpha=0.7)\n",
        "    ax1.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "    ax1.axhline(y=-15, color='orange', linestyle='--', alpha=0.5, label='Dry threshold')\n",
        "    ax1.axhline(y=15, color='blue', linestyle='--', alpha=0.5, label='Wet threshold')\n",
        "    ax1.set_xlabel('Year')\n",
        "    ax1.set_ylabel('Precipitation Anomaly (%)')\n",
        "    ax1.set_title('Growing Season Precipitation Anomaly')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add classification labels\n",
        "    for i, (year, classification) in enumerate(zip(yearly_df['Year'], yearly_df['Classification'])):\n",
        "        ax1.text(year, yearly_df['Anomaly_pct'].iloc[i] + 2, \n",
        "                classification.split()[0], ha='center', fontsize=8, rotation=45)\n",
        "    \n",
        "    # 2. Total precipitation by year\n",
        "    ax2 = axes[0, 1]\n",
        "    ax2.bar(yearly_df['Year'], yearly_df['Total_Precip_mm'], color='steelblue', alpha=0.7)\n",
        "    if len(yearly_df) > 0:\n",
        "        ax2.axhline(y=yearly_df['Normal_mm'].iloc[0], color='red', linestyle='--', \n",
        "                   label=f\"Normal ({yearly_df['Normal_mm'].iloc[0]:.0f} mm)\")\n",
        "    ax2.set_xlabel('Year')\n",
        "    ax2.set_ylabel('Precipitation (mm)')\n",
        "    ax2.set_title('Total Growing Season Precipitation')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Crop rotation timeline\n",
        "    ax3 = axes[1, 0]\n",
        "    if 'aafc_df' in locals() and len(aafc_df) > 0:\n",
        "        unique_crops = aafc_df['Primary_Crop'].unique()\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, len(unique_crops)))\n",
        "        crop_colors = dict(zip(unique_crops, colors))\n",
        "        \n",
        "        bars = ax3.bar(aafc_df['Year'], [1]*len(aafc_df), \n",
        "                      color=[crop_colors[crop] for crop in aafc_df['Primary_Crop']])\n",
        "        \n",
        "        for i, (year, crop) in enumerate(zip(aafc_df['Year'], aafc_df['Primary_Crop'])):\n",
        "            ax3.text(year, 0.5, crop[:10], ha='center', va='center', rotation=90, fontsize=8)\n",
        "        \n",
        "        ax3.set_xlabel('Year')\n",
        "        ax3.set_title('Crop Rotation History')\n",
        "        ax3.set_ylim(0, 1)\n",
        "        ax3.set_yticks([])\n",
        "    \n",
        "    # 4. Summary table\n",
        "    ax4 = axes[1, 1]\n",
        "    ax4.axis('off')\n",
        "    \n",
        "    # Combine AAFC and precipitation data\n",
        "    if 'aafc_df' in locals():\n",
        "        summary_data = []\n",
        "        for year in yearly_df['Year']:\n",
        "            crop_row = aafc_df[aafc_df['Year'] == year]\n",
        "            precip_row = yearly_df[yearly_df['Year'] == year]\n",
        "            \n",
        "            if not crop_row.empty and not precip_row.empty:\n",
        "                summary_data.append([\n",
        "                    year,\n",
        "                    crop_row.iloc[0]['Primary_Crop'][:15],\n",
        "                    f\"{precip_row.iloc[0]['Anomaly_pct']:.0f}%\",\n",
        "                    precip_row.iloc[0]['Classification'].split()[0]\n",
        "                ])\n",
        "        \n",
        "        if summary_data:\n",
        "            table = ax4.table(cellText=summary_data,\n",
        "                            colLabels=['Year', 'Crop', 'Precip Anomaly', 'Classification'],\n",
        "                            cellLoc='center',\n",
        "                            loc='center')\n",
        "            table.auto_set_font_size(False)\n",
        "            table.set_fontsize(9)\n",
        "            table.scale(1, 1.5)\n",
        "    \n",
        "    ax4.set_title('Combined Summary', fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('background_data_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n✓ Figure saved as 'background_data_analysis.png'\")\n",
        "else:\n",
        "    print(\"⚠ Run data extraction first\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Export Combined Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine all data into export format\n",
        "if aoi_geometry and 'aafc_df' in locals() and 'yearly_df' in locals():\n",
        "    \n",
        "    # Create combined dataset\n",
        "    export_data = []\n",
        "    \n",
        "    for year in yearly_df['Year']:\n",
        "        # Get crop data\n",
        "        crop_row = aafc_df[aafc_df['Year'] == year]\n",
        "        # Get precipitation data\n",
        "        precip_row = yearly_df[yearly_df['Year'] == year]\n",
        "        # Get monthly precipitation\n",
        "        monthly_precip = precip_df[precip_df['Year'] == year]\n",
        "        \n",
        "        row_data = {\n",
        "            'Year': year,\n",
        "            'AOI_Name': uploaded_filename if uploaded_filename else 'Unknown',\n",
        "        }\n",
        "        \n",
        "        # Add crop data\n",
        "        if not crop_row.empty:\n",
        "            row_data.update({\n",
        "                'Primary_Crop': crop_row.iloc[0]['Primary_Crop'],\n",
        "                'Primary_Crop_Code': crop_row.iloc[0]['Primary_Crop_Code'],\n",
        "                'Primary_Crop_Pct': crop_row.iloc[0]['Primary_Crop_Pct'],\n",
        "                'Secondary_Crop': crop_row.iloc[0]['Secondary_Crop']\n",
        "            })\n",
        "        else:\n",
        "            row_data.update({\n",
        "                'Primary_Crop': None,\n",
        "                'Primary_Crop_Code': None,\n",
        "                'Primary_Crop_Pct': None,\n",
        "                'Secondary_Crop': None\n",
        "            })\n",
        "        \n",
        "        # Add monthly precipitation\n",
        "        for month in range(4, 11):\n",
        "            month_data = monthly_precip[monthly_precip['Month'] == month]\n",
        "            if not month_data.empty:\n",
        "                month_name = calendar.month_name[month][:3]\n",
        "                row_data[f'{month_name}_Precip_mm'] = month_data.iloc[0]['Precipitation_mm']\n",
        "                row_data[f'{month_name}_Anomaly_pct'] = month_data.iloc[0].get('Anomaly_pct', None)\n",
        "            else:\n",
        "                month_name = calendar.month_name[month][:3]\n",
        "                row_data[f'{month_name}_Precip_mm'] = None\n",
        "                row_data[f'{month_name}_Anomaly_pct'] = None\n",
        "        \n",
        "        # Add seasonal summary\n",
        "        if not precip_row.empty:\n",
        "            row_data.update({\n",
        "                'Season_Total_Precip_mm': precip_row.iloc[0]['Total_Precip_mm'],\n",
        "                'Season_Normal_mm': precip_row.iloc[0]['Normal_mm'],\n",
        "                'Season_Anomaly_mm': precip_row.iloc[0]['Anomaly_mm'],\n",
        "                'Season_Anomaly_pct': precip_row.iloc[0]['Anomaly_pct'],\n",
        "                'Season_Classification': precip_row.iloc[0]['Classification']\n",
        "            })\n",
        "        else:\n",
        "            row_data.update({\n",
        "                'Season_Total_Precip_mm': None,\n",
        "                'Season_Normal_mm': None,\n",
        "                'Season_Anomaly_mm': None,\n",
        "                'Season_Anomaly_pct': None,\n",
        "                'Season_Classification': None\n",
        "            })\n",
        "        \n",
        "        export_data.append(row_data)\n",
        "    \n",
        "    # Create DataFrame\n",
        "    export_df = pd.DataFrame(export_data)\n",
        "    \n",
        "    # Save to CSV\n",
        "    output_filename = f\"background_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "    export_df.to_csv(output_filename, index=False)\n",
        "    \n",
        "    print(f\"✓ Data exported to: {output_filename}\")\n",
        "    print(f\"\\nExport contains {len(export_df)} years of data with {len(export_df.columns)} columns\")\n",
        "    print(\"\\nColumns included:\")\n",
        "    print(\" - Crop data (AAFC)\")\n",
        "    print(\" - Monthly precipitation (April-October)\")\n",
        "    print(\" - Seasonal totals and anomalies\")\n",
        "    print(\" - Classifications (Dry/Normal/Wet)\")\n",
        "    \n",
        "    # Display preview\n",
        "    print(\"\\nData Preview:\")\n",
        "    display(export_df.head())\n",
        "    \n",
        "    # Also save metadata\n",
        "    metadata = {\n",
        "        'aoi_file': uploaded_filename,\n",
        "        'aafc_years': f\"{aafc_start.value}-{aafc_end.value}\",\n",
        "        'precip_baseline': f\"{precip_baseline_start.value}-{precip_baseline_end.value}\",\n",
        "        'precip_analysis': f\"{precip_analysis_start.value}-{precip_analysis_end.value}\",\n",
        "        'export_date': datetime.now().isoformat(),\n",
        "        'n_years': len(export_df),\n",
        "        'columns': list(export_df.columns)\n",
        "    }\n",
        "    \n",
        "    metadata_filename = output_filename.replace('.csv', '_metadata.json')\n",
        "    with open(metadata_filename, 'w') as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "    \n",
        "    print(f\"\\n✓ Metadata saved to: {metadata_filename}\")\n",
        "    \n",
        "else:\n",
        "    print(\"⚠ Please complete data extraction before exporting\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook has extracted and combined:\n",
        "1. **AAFC Crop History** - Annual crop types for your AOI\n",
        "2. **ERA-5 Precipitation** - Monthly precipitation with anomaly analysis\n",
        "3. **Classifications** - Dry/Normal/Wet year categorization\n",
        "\n",
        "The exported CSV file can now be used in your reclamation analysis to:\n",
        "- Account for crop rotation patterns\n",
        "- Normalize performance metrics for weather conditions\n",
        "- Identify years with abnormal precipitation that may affect vegetation\n",
        "- Provide context for interpreting reclamation success"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "# Oilfield Reclamation Site Assessment Using AlphaEarth Foundations v4\n",
    "\n",
    "**Objective:** Use Google's AlphaEarth Foundation 64D embeddings to assess reclamation success at oilfield lease sites by comparing to healthy regional cropland references.\n",
    "\n",
    "**Key Fixes in v4:**\n",
    "- Fixed AlphaEarth band naming (uses A00-A63 format)\n",
    "- Added AOI intersection with image footprint to handle edge cases\n",
    "- Graceful handling of partial coverage and null pixels\n",
    "- Robust comparison of lease vs field background over time\n",
    "\n",
    "**Methodology:**\n",
    "1. Upload field boundary (arable land) and lease boundary polygons\n",
    "2. Extract AAFC Annual Crop Inventory data to identify crop type per year\n",
    "3. Extract AlphaEarth embeddings for lease and background (field minus lease)\n",
    "4. Compare lease embeddings vs background field embeddings over time\n",
    "5. Track recovery trajectory using cosine similarity\n",
    "\n",
    "**Key Datasets:**\n",
    "- AlphaEarth Foundation (AEF): `GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL` (64D embeddings, 10m resolution)\n",
    "- AAFC Annual Crop Inventory: `AAFC/ACI` (30m resolution, 2009-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import ee\n",
    "import geemap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "import os\n",
    "from io import BytesIO\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate and initialize Earth Engine\n",
    "# Change 'jessemapping' to your Earth Engine project ID if needed\n",
    "print(\"Authenticating with Earth Engine...\")\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project=\"jessemapping\")\n",
    "print(\"✓ Earth Engine initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fiona geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Upload Boundary Files\n",
    "\n",
    "Upload your polygon files (KML, GeoJSON, or SHP/ZIP):\n",
    "- **Field Boundary:** The clean agricultural area (quarter section minus non-arable areas)\n",
    "- **Lease Boundary:** The disturbed oilfield lease site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store uploaded geometries\n",
    "field_boundary = None\n",
    "lease_boundary = None\n",
    "\n",
    "def parse_file(content, filename, name):\n",
    "    \"\"\"Parse uploaded file and return Earth Engine geometry\"\"\"\n",
    "    temp_path = f'/tmp/{filename}'\n",
    "    os.makedirs('/tmp', exist_ok=True)\n",
    "\n",
    "    with open(temp_path, 'wb') as f:\n",
    "        f.write(content)\n",
    "\n",
    "    try:\n",
    "        if filename.endswith('.kml'):\n",
    "            import fiona\n",
    "            fiona.drvsupport.supported_drivers['KML'] = 'r'\n",
    "            import geopandas as gpd\n",
    "            gdf = gpd.read_file(temp_path, driver='KML')\n",
    "        elif filename.endswith(('.geojson', '.json')):\n",
    "            import geopandas as gpd\n",
    "            gdf = gpd.read_file(temp_path)\n",
    "        elif filename.endswith('.zip'):\n",
    "            with zipfile.ZipFile(temp_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall('/tmp/shp_extract')\n",
    "            shp_file = None\n",
    "            for root, dirs, files in os.walk('/tmp/shp_extract'):\n",
    "                for file in files:\n",
    "                    if file.endswith('.shp'):\n",
    "                        shp_file = os.path.join(root, file)\n",
    "                        break\n",
    "                if shp_file:\n",
    "                    break\n",
    "            if shp_file:\n",
    "                import geopandas as gpd\n",
    "                gdf = gpd.read_file(shp_file)\n",
    "            else:\n",
    "                raise ValueError(\"No .shp file found in the uploaded zip archive.\")\n",
    "        elif filename.endswith('.shp'):\n",
    "            import geopandas as gpd\n",
    "            gdf = gpd.read_file(temp_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {filename}\")\n",
    "\n",
    "        # Ensure WGS84 projection\n",
    "        if gdf.crs and gdf.crs.to_string() != 'EPSG:4326':\n",
    "            gdf = gdf.to_crs('EPSG:4326')\n",
    "\n",
    "        # Convert to GeoJSON\n",
    "        geojson = json.loads(gdf.to_json())\n",
    "\n",
    "        if geojson['features']:\n",
    "            geometry = geojson['features'][0]['geometry']\n",
    "            ee_geom = ee.Geometry(geometry)\n",
    "            print(f\"✓ {name} parsed successfully from {filename}\")\n",
    "            return ee_geom\n",
    "        else:\n",
    "            raise ValueError(f\"No features found in {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing {name} file '{filename}': {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "        if os.path.exists('/tmp/shp_extract'):\n",
    "            import shutil\n",
    "            shutil.rmtree('/tmp/shp_extract')\n",
    "\n",
    "def upload_files():\n",
    "    global field_boundary, lease_boundary\n",
    "    from google.colab import files\n",
    "\n",
    "    print(\"Please upload your Field Boundary file (KML, GeoJSON, SHP/ZIP)...\")\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    for filename, content in uploaded.items():\n",
    "        field_boundary = parse_file(content, filename, \"Field Boundary\")\n",
    "        break\n",
    "\n",
    "    print(\"\\nPlease upload your Lease Boundary file (KML, GeoJSON, SHP/ZIP)...\")\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    for filename, content in uploaded.items():\n",
    "        lease_boundary = parse_file(content, filename, \"Lease Boundary\")\n",
    "        break\n",
    "\n",
    "    if field_boundary and lease_boundary:\n",
    "        print(\"\\n✓ Both boundaries loaded successfully!\")\n",
    "    else:\n",
    "        print(\"\\n✗ Error processing files. Check the messages above.\")\n",
    "\n",
    "upload_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Analysis Years\n",
    "\n",
    "Select which years you want to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure analysis years - modify as needed\n",
    "# AlphaEarth Foundation data is available from 2017 onwards\n",
    "ANALYSIS_YEARS = list(range(2017, 2024))  # 2017 to 2023\n",
    "\n",
    "print(f\"Years to analyze: {ANALYSIS_YEARS}\")\n",
    "print(f\"\\nNote: AlphaEarth Foundation data is available from 2017 onwards.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Crop History (AAFC Annual Crop Inventory)\n",
    "\n",
    "Identify what crop was grown in the field for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAFC crop classification lookup\n",
    "CROP_CLASSES = {\n",
    "    10: 'Cloud',\n",
    "    20: 'Water',\n",
    "    30: 'Exposed Land and Barren',\n",
    "    34: 'Urban and Developed',\n",
    "    35: 'Greenhouses',\n",
    "    50: 'Shrubland',\n",
    "    80: 'Wetland',\n",
    "    85: 'Peatland',\n",
    "    110: 'Grassland',\n",
    "    120: 'Agriculture (undifferentiated)',\n",
    "    122: 'Pasture and Forages',\n",
    "    130: 'Too Wet to be Seeded',\n",
    "    131: 'Fallow',\n",
    "    132: 'Cereals',\n",
    "    133: 'Barley',\n",
    "    134: 'Other Grains',\n",
    "    135: 'Millet',\n",
    "    136: 'Oats',\n",
    "    137: 'Rye',\n",
    "    138: 'Spelt',\n",
    "    139: 'Triticale',\n",
    "    140: 'Wheat',\n",
    "    141: 'Switchgrass',\n",
    "    142: 'Sorghum',\n",
    "    143: 'Quinoa',\n",
    "    145: 'Winter Wheat',\n",
    "    146: 'Spring Wheat',\n",
    "    147: 'Corn',\n",
    "    148: 'Tobacco',\n",
    "    149: 'Ginseng',\n",
    "    150: 'Oilseeds',\n",
    "    151: 'Borage',\n",
    "    152: 'Camelina',\n",
    "    153: 'Canola and Rapeseed',\n",
    "    154: 'Flaxseed',\n",
    "    155: 'Mustard',\n",
    "    156: 'Safflower',\n",
    "    157: 'Sunflower',\n",
    "    158: 'Soybeans',\n",
    "    160: 'Pulses',\n",
    "    161: 'Other Pulses',\n",
    "    162: 'Peas',\n",
    "    163: 'Chickpeas',\n",
    "    167: 'Beans',\n",
    "    168: 'Fababeans',\n",
    "    174: 'Lentils',\n",
    "    175: 'Vegetables',\n",
    "    176: 'Tomatoes',\n",
    "    177: 'Potatoes',\n",
    "    178: 'Sugarbeets',\n",
    "    179: 'Other Vegetables',\n",
    "    180: 'Fruits',\n",
    "    181: 'Berries',\n",
    "    182: 'Blueberry',\n",
    "    183: 'Cranberry',\n",
    "    185: 'Other Berry',\n",
    "    188: 'Orchards',\n",
    "    189: 'Other Fruits',\n",
    "    190: 'Vineyards',\n",
    "    191: 'Hops',\n",
    "    192: 'Sod',\n",
    "    193: 'Herbs',\n",
    "    194: 'Nursery',\n",
    "    195: 'Buckwheat',\n",
    "    196: 'Canaryseed',\n",
    "    197: 'Hemp',\n",
    "    198: 'Vetch',\n",
    "    199: 'Other Crops',\n",
    "    200: 'Forest (undifferentiated)',\n",
    "    210: 'Coniferous',\n",
    "    220: 'Broadleaf',\n",
    "    230: 'Mixedwood'\n",
    "}\n",
    "\n",
    "def get_crop_history(geometry, years, scale=30, sample_size=500):\n",
    "    \"\"\"\n",
    "    Extract the most frequent crop type within a geometry for each year.\n",
    "    \"\"\"\n",
    "    aafc = ee.ImageCollection('AAFC/ACI')\n",
    "    allowed_codes = list(CROP_CLASSES.keys())\n",
    "    crop_history = {}\n",
    "\n",
    "    for year in years:\n",
    "        crop_img = aafc.filter(ee.Filter.date(f'{year}-01-01', f'{year}-12-31')).first()\n",
    "\n",
    "        if crop_img:\n",
    "            samples = crop_img.select('landcover').sample(\n",
    "                region=geometry,\n",
    "                scale=scale,\n",
    "                numPixels=sample_size,\n",
    "                seed=year,\n",
    "                geometries=False\n",
    "            )\n",
    "\n",
    "            sample_list = samples.aggregate_array('landcover').getInfo()\n",
    "            filtered_samples = [code for code in sample_list if code in allowed_codes]\n",
    "\n",
    "            if filtered_samples:\n",
    "                from collections import Counter\n",
    "                code_counts = Counter(filtered_samples)\n",
    "                most_common = code_counts.most_common(1)\n",
    "\n",
    "                if most_common:\n",
    "                    crop_code = most_common[0][0]\n",
    "                    crop_name = CROP_CLASSES.get(crop_code, f'Unknown ({crop_code})')\n",
    "                    crop_history[year] = {'code': crop_code, 'name': crop_name}\n",
    "                else:\n",
    "                    crop_history[year] = {'code': None, 'name': 'No Valid Crop Found'}\n",
    "            else:\n",
    "                print(f\"Warning: No sampled pixels had an allowed crop code for year {year}.\")\n",
    "                crop_history[year] = {'code': None, 'name': 'No Allowed Crop Sampled'}\n",
    "\n",
    "    return crop_history\n",
    "\n",
    "print(\"✓ Crop history extraction function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract crop history for the field\n",
    "if field_boundary:\n",
    "    print(\"Extracting crop history from AAFC Annual Crop Inventory...\")\n",
    "    crop_history = get_crop_history(field_boundary, ANALYSIS_YEARS)\n",
    "\n",
    "    print(\"\\nCrop History:\")\n",
    "    crop_df = pd.DataFrame.from_dict(crop_history, orient='index')\n",
    "    crop_df.index.name = 'Year'\n",
    "    display(crop_df)\n",
    "else:\n",
    "    print(\"Please upload field boundaries first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AlphaEarth Foundation Embedding Extraction\n",
    "\n",
    "This is the core analysis section. Key features:\n",
    "- **Correct band naming:** Uses A00-A63 format (not embedding_0-63)\n",
    "- **AOI intersection:** Clips geometries to valid image coverage\n",
    "- **Null handling:** Gracefully handles edge pixels with no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AlphaEarth Foundation collection\n",
    "aef_collection = ee.ImageCollection(\"GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL\")\n",
    "\n",
    "# IMPORTANT: AlphaEarth bands are named A00-A63 (not embedding_0-63)\n",
    "AEF_BAND_NAMES = [f'A{i:02d}' for i in range(64)]\n",
    "\n",
    "print(f\"AlphaEarth band names: {AEF_BAND_NAMES[:5]}... to ...{AEF_BAND_NAMES[-3:]}\")\n",
    "print(f\"Total bands: {len(AEF_BAND_NAMES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(geometry, year, scale=10, min_pixels=10):\n",
    "    \"\"\"\n",
    "    Extract mean 64D embedding for a geometry and year.\n",
    "    Uses selfMask() to automatically exclude null/masked pixels.\n",
    "    \n",
    "    Args:\n",
    "        geometry: ee.Geometry\n",
    "        year: int (2017-2024)\n",
    "        scale: int (default 10m)\n",
    "        min_pixels: int (minimum valid pixels required, default 10)\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'embedding' (64D array or None), 'pixel_count', 'year', and 'status'\n",
    "    \"\"\"\n",
    "    # Filter to specific year\n",
    "    aef_filtered = aef_collection.filter(ee.Filter.date(f'{year}-01-01', f'{year}-12-31'))\n",
    "    \n",
    "    # Check if any images exist for this year\n",
    "    try:\n",
    "        image_count = aef_filtered.size().getInfo()\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR checking image count: {e}\")\n",
    "        return {\n",
    "            'embedding': None,\n",
    "            'pixel_count': 0,\n",
    "            'year': year,\n",
    "            'status': 'error'\n",
    "        }\n",
    "    \n",
    "    if image_count == 0:\n",
    "        print(f\"    WARNING: No AlphaEarth images found for year {year}\")\n",
    "        return {\n",
    "            'embedding': None,\n",
    "            'pixel_count': 0,\n",
    "            'year': year,\n",
    "            'status': 'no_data'\n",
    "        }\n",
    "    \n",
    "    aef_year = aef_filtered.first()\n",
    "    \n",
    "    # Select the correct bands (A00-A63) and apply selfMask\n",
    "    # selfMask() ensures we only use valid pixels (ignores masked/null areas)\n",
    "    aef_selected = aef_year.select(AEF_BAND_NAMES).selfMask()\n",
    "    \n",
    "    # Compute mean embedding across the geometry\n",
    "    # The selfMask ensures null pixels are excluded automatically\n",
    "    try:\n",
    "        stats = aef_selected.reduceRegion(\n",
    "            reducer=ee.Reducer.mean().combine(\n",
    "                reducer2=ee.Reducer.count(),\n",
    "                sharedInputs=True\n",
    "            ),\n",
    "            geometry=geometry,\n",
    "            scale=scale,\n",
    "            maxPixels=1e9,\n",
    "            bestEffort=True\n",
    "        )\n",
    "        result = stats.getInfo()\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR in reduceRegion: {e}\")\n",
    "        return {\n",
    "            'embedding': None,\n",
    "            'pixel_count': 0,\n",
    "            'year': year,\n",
    "            'status': 'reduce_failed'\n",
    "        }\n",
    "    \n",
    "    if not result:\n",
    "        print(f\"    WARNING: Empty result from reduceRegion for year {year}\")\n",
    "        return {\n",
    "            'embedding': None,\n",
    "            'pixel_count': 0,\n",
    "            'year': year,\n",
    "            'status': 'reduce_failed'\n",
    "        }\n",
    "    \n",
    "    # Get pixel count first\n",
    "    pixel_count = result.get('A00_count', None)\n",
    "    if pixel_count is not None:\n",
    "        try:\n",
    "            pixel_count = int(pixel_count)\n",
    "        except (TypeError, ValueError):\n",
    "            pixel_count = 0\n",
    "    else:\n",
    "        pixel_count = 0\n",
    "    \n",
    "    # Check if we have enough valid pixels\n",
    "    if pixel_count < min_pixels:\n",
    "        print(f\"    WARNING: Only {pixel_count} valid pixels (need at least {min_pixels}) for year {year}\")\n",
    "        return {\n",
    "            'embedding': None,\n",
    "            'pixel_count': pixel_count,\n",
    "            'year': year,\n",
    "            'status': 'insufficient_pixels'\n",
    "        }\n",
    "    \n",
    "    # Extract embedding values with proper type handling\n",
    "    embedding_values = []\n",
    "    null_count = 0\n",
    "    for i in range(64):\n",
    "        val = result.get(f'A{i:02d}_mean', None)\n",
    "        if val is None:\n",
    "            embedding_values.append(0.0)\n",
    "            null_count += 1\n",
    "        else:\n",
    "            try:\n",
    "                embedding_values.append(float(val))\n",
    "            except (TypeError, ValueError):\n",
    "                embedding_values.append(0.0)\n",
    "                null_count += 1\n",
    "    \n",
    "    # Check if too many null values in embedding\n",
    "    if null_count > 32:  # More than half the bands are null\n",
    "        print(f\"    WARNING: {null_count}/64 bands returned null for year {year}\")\n",
    "        return {\n",
    "            'embedding': None,\n",
    "            'pixel_count': pixel_count,\n",
    "            'year': year,\n",
    "            'status': 'partial_data'\n",
    "        }\n",
    "    \n",
    "    embedding = np.array(embedding_values, dtype=np.float64)\n",
    "    \n",
    "    # Final validation: check embedding is not all zeros\n",
    "    if np.all(embedding == 0):\n",
    "        print(f\"    WARNING: All-zero embedding for year {year}\")\n",
    "        return {\n",
    "            'embedding': None,\n",
    "            'pixel_count': pixel_count,\n",
    "            'year': year,\n",
    "            'status': 'zero_embedding'\n",
    "        }\n",
    "    \n",
    "    # Success!\n",
    "    return {\n",
    "        'embedding': embedding,\n",
    "        'pixel_count': pixel_count,\n",
    "        'year': year,\n",
    "        'status': 'success'\n",
    "    }\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Compute cosine similarity between two vectors\"\"\"\n",
    "    if a is None or b is None:\n",
    "        return None\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    \n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    \"\"\"Compute Euclidean distance between two vectors\"\"\"\n",
    "    if a is None or b is None:\n",
    "        return None\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "\n",
    "print(\"✓ AlphaEarth embedding extraction functions ready\")\n",
    "print(\"✓ Band naming: A00-A63 (correct format)\")\n",
    "print(\"✓ selfMask() applied to exclude null pixels automatically\")\n",
    "print(\"✓ Returns None for failed extractions (comparison loop will skip)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Reclamation Analysis\n",
    "\n",
    "Compare lease embeddings to background field embeddings over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the reclamation analysis\n",
    "if field_boundary and lease_boundary and crop_history:\n",
    "    print(\"Running reclamation analysis...\")\n",
    "    print(\"Comparing lease area to background field (field minus lease)\\n\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Calculate background area (field minus lease)\n",
    "    # This represents the healthy/undisturbed reference within the same field\n",
    "    background_area = field_boundary.difference(lease_boundary)\n",
    "    \n",
    "    # Get area info\n",
    "    try:\n",
    "        field_area_ha = field_boundary.area(10).divide(10000).getInfo()\n",
    "        lease_area_ha = lease_boundary.area(10).divide(10000).getInfo()\n",
    "        background_area_ha = background_area.area(10).divide(10000).getInfo()\n",
    "        \n",
    "        print(f\"Field area: {field_area_ha:.2f} hectares\")\n",
    "        print(f\"Lease area: {lease_area_ha:.2f} hectares\")\n",
    "        print(f\"Background area: {background_area_ha:.2f} hectares\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not calculate areas: {e}\\n\")\n",
    "    \n",
    "    for year in sorted(crop_history.keys()):\n",
    "        crop_info = crop_history[year]\n",
    "        print(f\"\\nProcessing {year} - {crop_info['name']}...\")\n",
    "        \n",
    "        try:\n",
    "            # Extract embeddings for lease area\n",
    "            print(\"  - Extracting lease embeddings...\")\n",
    "            lease_emb = get_embeddings(lease_boundary, year)\n",
    "            print(f\"    Status: {lease_emb['status']}, Pixels: {lease_emb['pixel_count']}\")\n",
    "            \n",
    "            # Extract embeddings for background (field minus lease)\n",
    "            print(\"  - Extracting background embeddings...\")\n",
    "            background_emb = get_embeddings(background_area, year)\n",
    "            print(f\"    Status: {background_emb['status']}, Pixels: {background_emb['pixel_count']}\")\n",
    "            \n",
    "            # Check if we have valid embeddings for both\n",
    "            if lease_emb['status'] != 'success' or background_emb['status'] != 'success':\n",
    "                print(f\"  ⚠ Skipping {year}: insufficient valid pixels\")\n",
    "                continue\n",
    "            \n",
    "            # Compute similarity between lease and background\n",
    "            similarity = cosine_similarity(lease_emb['embedding'], background_emb['embedding'])\n",
    "            distance = euclidean_distance(lease_emb['embedding'], background_emb['embedding'])\n",
    "            \n",
    "            results.append({\n",
    "                'year': year,\n",
    "                'crop': crop_info['name'],\n",
    "                'crop_code': crop_info['code'],\n",
    "                'lease_pixels': lease_emb['pixel_count'],\n",
    "                'background_pixels': background_emb['pixel_count'],\n",
    "                'cosine_similarity': similarity,\n",
    "                'euclidean_distance': distance,\n",
    "                'recovery_score': similarity,\n",
    "                'recovery_percent': similarity * 100\n",
    "            })\n",
    "            \n",
    "            print(f\"  ✓ Cosine Similarity (Lease vs Background): {similarity:.4f}\")\n",
    "            print(f\"  ✓ Euclidean Distance: {distance:.2f}\")\n",
    "            print(f\"  ✓ Recovery Score: {similarity:.2%}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if len(results_df) > 0:\n",
    "        print(\"\\nRecovery scores show how similar the lease is to the healthy field background:\")\n",
    "        print(\"• 90-100%: Excellent recovery - lease performing like healthy field\")\n",
    "        print(\"• 80-90%: Good recovery - minor differences from field\")\n",
    "        print(\"• 70-80%: Moderate recovery - noticeable differences\")\n",
    "        print(\"• <70%: Poor recovery - significant differences from field\\n\")\n",
    "        display(results_df)\n",
    "    else:\n",
    "        print(\"\\nNo successful analyses completed. Please check the messages above.\")\n",
    "else:\n",
    "    print(\"Please complete all previous steps first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot recovery trajectory over time\n",
    "if 'results_df' in dir() and len(results_df) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot 1: Cosine Similarity over time\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(results_df['year'], results_df['cosine_similarity'], 'b-o', linewidth=2, markersize=8)\n",
    "    ax1.axhline(y=0.9, color='g', linestyle='--', alpha=0.7, label='Excellent (90%)')\n",
    "    ax1.axhline(y=0.8, color='orange', linestyle='--', alpha=0.7, label='Good (80%)')\n",
    "    ax1.axhline(y=0.7, color='r', linestyle='--', alpha=0.7, label='Moderate (70%)')\n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Cosine Similarity (Lease vs Background)')\n",
    "    ax1.set_title('Reclamation Recovery Trajectory')\n",
    "    ax1.legend(loc='lower right')\n",
    "    ax1.set_ylim(0, 1.05)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add crop labels\n",
    "    for idx, row in results_df.iterrows():\n",
    "        ax1.annotate(row['crop'][:10], (row['year'], row['cosine_similarity']), \n",
    "                    textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=8, rotation=45)\n",
    "    \n",
    "    # Plot 2: Euclidean Distance over time\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(results_df['year'], results_df['euclidean_distance'], 'r-s', linewidth=2, markersize=8)\n",
    "    ax2.set_xlabel('Year')\n",
    "    ax2.set_ylabel('Euclidean Distance (Lower = More Similar)')\n",
    "    ax2.set_title('Spectral Distance: Lease vs Background')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(f\"  Mean Cosine Similarity: {results_df['cosine_similarity'].mean():.4f}\")\n",
    "    print(f\"  Min Cosine Similarity: {results_df['cosine_similarity'].min():.4f} ({results_df.loc[results_df['cosine_similarity'].idxmin(), 'year']})\")\n",
    "    print(f\"  Max Cosine Similarity: {results_df['cosine_similarity'].max():.4f} ({results_df.loc[results_df['cosine_similarity'].idxmax(), 'year']})\")\n",
    "    \n",
    "    # Trend analysis\n",
    "    if len(results_df) > 2:\n",
    "        first_half = results_df['cosine_similarity'][:len(results_df)//2].mean()\n",
    "        second_half = results_df['cosine_similarity'][len(results_df)//2:].mean()\n",
    "        trend = \"improving\" if second_half > first_half else \"declining\" if second_half < first_half else \"stable\"\n",
    "        print(f\"\\n  Trend: Recovery appears to be {trend}\")\n",
    "        print(f\"    Early period average: {first_half:.4f}\")\n",
    "        print(f\"    Later period average: {second_half:.4f}\")\n",
    "else:\n",
    "    print(\"No results to visualize. Run the analysis first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Display Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive map with boundaries\n",
    "if field_boundary and lease_boundary:\n",
    "    # Get center point for map\n",
    "    center = field_boundary.centroid().coordinates().getInfo()\n",
    "    \n",
    "    Map = geemap.Map(center=[center[1], center[0]], zoom=15)\n",
    "    \n",
    "    # Add field boundary (green)\n",
    "    Map.addLayer(\n",
    "        field_boundary, \n",
    "        {'color': '00FF00', 'fillColor': '00FF0022'}, \n",
    "        'Field Boundary'\n",
    "    )\n",
    "    \n",
    "    # Add lease boundary (red)\n",
    "    Map.addLayer(\n",
    "        lease_boundary, \n",
    "        {'color': 'FF0000', 'fillColor': 'FF000044'}, \n",
    "        'Lease Boundary'\n",
    "    )\n",
    "    \n",
    "    # Add background area (blue) - field minus lease\n",
    "    background_area = field_boundary.difference(lease_boundary)\n",
    "    Map.addLayer(\n",
    "        background_area, \n",
    "        {'color': '0000FF', 'fillColor': '0000FF22'}, \n",
    "        'Background (Field - Lease)'\n",
    "    )\n",
    "    \n",
    "    Map.addLayerControl()\n",
    "    display(Map)\n",
    "else:\n",
    "    print(\"Please upload boundaries first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV\n",
    "if 'results_df' in dir() and len(results_df) > 0:\n",
    "    output_filename = 'reclamation_analysis_results.csv'\n",
    "    results_df.to_csv(output_filename, index=False)\n",
    "    print(f\"Results exported to {output_filename}\")\n",
    "    \n",
    "    # Download link for Colab\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        files.download(output_filename)\n",
    "    except:\n",
    "        print(f\"File saved locally: {output_filename}\")\n",
    "else:\n",
    "    print(\"No results to export. Run the analysis first.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
